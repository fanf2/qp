never mind the quadbits, feel the width!
========================================

benchmarking wide-fanout versions of qp tries
---------------------------------------------

The Q in "qp trie" comes from "quadbit", i.e. a nibble. The key is
indexed 4 bits at a time, and each chunk of 4 bits is used to index a
trie branch node. Each branch node has a bitmap which is 2^4 == 16
bits wide, identifying which child nodes ("twigs") are present.

I originally chose to index by nibbles for two reasons: they are easy
to pull out of the key, and the bitmap easily fits in a word with room
for a key index.

If branch nodes are wider, then the trie can be shallower on average,
which should mean lookups are faster.

If we index keys by 5-bit chunks we pay a penalty for more complicated
indexing. If we index keys by 6-bit chunks, trie nodes have to be
bigger so we pay a memory overhead penalty. How do these costs compare
to the benefits of wider branches?

(The next two sections expand on the downsides; skip to "results" for
the tl;dr.)

five-bit fields are fiddly
--------------------------

If we use the key 5 bits at a time, the bitmap is 2^5 == 32 bits. This
leaves room for a 28 bit index (limiting keys to 256 Mbytes), three
bits to store the shift/alignment of the 5 bit field relative to 8 bit
bytes, and a 1 bit branch/leaf flag.

When indexing by 4 bit chunks, we only need to look at one byte of key
at a time. For larger chunks we may need to extract a chunk that
overlaps two bytes. We treat the key as a string of chunks, which have
pre-determined alignments. This allows us to slot new branch nodes
into the trie and guarantee that the chunk used to index the new
branch does not overlap its parent or children.

The diagram below shows the correspondence between byte indexes (`i`)
and chunk alignment shifts (`s`). The shift value is how much to shift
the chunk left to move it to the top of its byte, so shift values and
indexes increase from left to right. This fact is used when working
out how deep a new branch node is; for instance, when `i%5==1` the
possible shifts are 2 and 7, so the branch for the chunk with shift 2
has to be a parent of 7.

     i%5==0  i%5==1  i%5==2  i%5==3  i%5==4
    |       |       |       |       |       | bytes
    7654321076543210765432107654321076543210
    |    |    |    |    |    |    |    |    | chunks
     s=0  s=5  s=2  s=7  s=4  s=1  s=6  s=3

When we are working out which is the first chunk where two keys differ
(so we can work out where to insert a new branch) we start off by
scanning to find the first byte that differs. But, if the first
differing bits are in the top of the byte, they can be in a chunk
which overlaps the preceding byte. In those cases we have to subtract
one from the index byte.

six-bit chunks blow the size budget
-----------------------------------

If we use the key 6 bits at a time, the bitmap is 2^6 == 64 bits. In
this case we have to expand trie nodes to three words: bitmap, index,
and twigs pointer. This means there's now a word of wasted space in
the leaf nodes.

My code borrows the caller's existing pointer to the key, rather than
taking a copy of the key for its own use. If I change it to take a
copy, then I could save the wasted space in big leaf nodes by using it
to store short keys inline. But for now I've just done enough of a
proof of concept to see what is the effect of wider branches, without
re-doing the memory ownership model.

The other potential loss for 6-bit chunks is the potential size of the
twig array, up to 3*8*64 = 1536 bytes. This is 24 cache lines, so
prefetching is unlikely to be much help if the twig index is large,
because the prefetch guess is way off.

benchmark process
-----------------

The data sets I use are:

* `in-b9`: words extracted from the BIND-9 source code
	* 63k lines, 784k bytes, av. len. 12.3
	* lots of common prefixes

* `in-dns`: list of domain names under cam.ac.uk.
	* 314k lines, 14 049k bytes, av. len. 44.7
	* would be more trie-like to reverse these keys!

* `in-usdw`: `/usr/share/dict/words`
	* 236k lines, 2 493k bytes, av. len. 10.7
	* English dictionary

* `top-1m`: the Alexa top million web site list
	* 1000k lines, 15 559k bytes, av. len. 15.6
	* numeric rankings removed

A benchmark run takes four time measurements (lower is better): read
the data into memory (without timing), "load" it into the trie,
"search" for 1 000 000 pseudorandomly selected keys, "mutate" (i.e.
add or delete) 1 000 000 pseudorandomly selected keys, reload any
missing items (without timing), then "free" the entire trie. A
benchmark run has an explicit PRNG seed.

Each benchmark iteration has a fixed PRNG seed. It performs benchmark
runs with every data set and every version of the data structure under
test (4 x 4 runs). The versions of the data structure are:

* cb: crit-bit tries
* qp: quadbit popcount patricia tries
* fp: 5-bit version of qp tries
* wp: 6-bit version of qp tries

Benchmarks are iterated and we take the mean.

results
-------

Overall, 5-bit chunks win over 4-bit chunks. 6-bit chunks have
mixed results, depending on data and test system.

* MacBook
    * Core 2 Duo, aluminium unibody late 2008
    * Apple LLVM version 7.0.0 (clang-700.0.72)
    * `-O3 -march=native -mtune=native`
    * `__builtin_popcount`

MacBook times:

         |   in-b9  in-dns in-usdw  top-1m
         |
      cb |   0.045   0.189   0.081   1.482   load
      qp |   0.051   0.243   0.133   1.183
      fp |   0.046   0.237   0.130   1.140
      wp |   0.051   0.237   0.128   1.138
         |
      cb |   0.484   1.101   0.865   1.744   search
      qp |   0.379   0.859   0.736   1.174
      fp |   0.368   0.870   0.692   1.050
      wp |   0.427   0.854   0.706   0.978
         |
      cb |   0.519   1.317   1.092   1.873   mutate
      wp |   0.465   0.981   0.863   1.324
      fp |   0.434   0.978   0.788   1.201
      wp |   0.475   0.978   0.822   1.140
         |
      cb |   0.030   0.174   0.095   1.494   free
      qp |   0.028   0.157   0.102   1.033
      fp |   0.027   0.156   0.096   0.921
      wp |   0.030   0.158   0.100   0.954
