Prefetching tries
=================

The inner loop in qp trie lookups is roughly

	while(isbranch(t)) {
		__builtin_prefetch(t->twigs);
		b = 1 << nibble(key, t->index);
		if(!(t->bitmap & b)) return(NULL);
		t = t->twigs[popcount(t->bitmap & b-1)];
	}

The efficiency of this loop depends on how quickly we can get from one
indirection down the trie to the next. There is quite a lot of work in
the loop, enough to slow it down significantly compared to the
crit-bit search loop. Although qp tries are half the depth of crit-bit
tries on average, they don't run twice as fast. The prefetch
compensates in a big way: without it, qp tries are about 10% faster;
with it they are about 30% faster.

One of the inspirations of qp tries was Phil Bagwell's hash array
mapped tries. HAMTs use the same popcount trick, but instead of using
the PATRICIA method of skipping redundant branch nodes, they hash the
key and use the hash as the trie index. The hashes should very rarely
collide, so redundant branches should also be rare.
